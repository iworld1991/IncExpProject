{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A model of learning of the income process\n",
    "\n",
    "This notebook experiments multiple dimensions via which agents misspecify the model of income leading to following empirical patterns of subjective income risk\n",
    "\n",
    "- Higher realizations corresponding to lower perceived risks \n",
    "- Older age corresponds to lower uncertainty \n",
    "- Cohort-specific uncertainty depending on the past realization of the income dispersion of the group \n",
    "- Asymmetry in the effect of realization of shocks, i.e. positive shocks brings about lower uncertainty and higher reduces the uncerainty. \n",
    "- Interplay between income realizations and uncertainty, i.e. extrapolative from the first moment to the second "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Income process and baseline model of learning  \n",
    "\n",
    "We start by defining an AR(1) process of the individual income. In particular, the income of individual $i$ from the cohort $c$ at time $t$ depends on her previous-period income with a persistence parameter of $\\rho$ and an individual and time-specific shock $\\epsilon_{i,c,t}$. \n",
    "\n",
    "\\begin{eqnarray}\n",
    "y_{i,c,t} = \\rho y_{i,c,t-1} + \\epsilon_{i,c,t}\n",
    "\\end{eqnarray}\n",
    "\n",
    "I define cohort $c$ to be measured by the year of entry in the job market. It is assumed that the $\\rho$ is the same across all inviduals. Also, I assume the income shock $\\epsilon_{i,c,t}$ to be i.i.d., namely independent across individuals and the time,and with an identical variance, as defined in the equation below. (Later sections will relax this assumption by allowing for cross-sectional correlation, namely some aggregate risks.)\n",
    "\n",
    "\\begin{eqnarray}\n",
    "E(\\epsilon_{t}'\\epsilon_{t}|Y_{t-1}) = \\sigma^2 I_n \\quad \\forall t \n",
    "\\end{eqnarray}\n",
    "\n",
    "where $\\sigma^2$ is the volatility of income shock and $I_n$ is an identity matrix whose length is the number of agents in the economy, $n$. Although income volatility is not cohort-specific, any past shock still has created different impacts on the young and old generations because their length of the proefessional career are different. This is reminiscent of <cite data-cite=\"bansal2004risks\">Storesletten et al. (2004)</cite>. Since both $\\rho$ and $\\sigma^2$ are not cohort-specific, I drop the subscript $c$ from now on to avoid clustering. \n",
    "\n",
    "Both $\\rho$ and $\\sigma$ are \"true\" parameters only known by the modeler, but unknown by agents in the economy. Individual $i$ learns about the income process by ``running'' a regression based on the model above using a limited sample from her past experience starting from the year of entering the job market till $t$. Critically, for this paper's purpose,  I allow the experience used for learning to include both her own and others' past income over the same period. It is admittedly bizarre to assume individual agents have access to the whole population's income. A more realistic assumption could be that only a small cross-sectional sample is available to the agent. Any scope of cross-sectional social learning suffices for the point to be made in this paper.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "import numpy.linalg as lg\n",
    "from scipy.special import erf \n",
    "import scipy.linalg as splg\n",
    "import pandas as pd\n",
    "from numba import njit\n",
    "#from numba import int32,int64, float32,float64, types,typed,typeof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ar_paras = np.array([0.95,0.1])\n",
    "typeof(ar_paras)\n",
    "\n",
    "spec = [\n",
    "    ('ar_paras',typeof(ar_paras)),  # a simple scalar field\n",
    "    ('rho', float64),                       # an array field\n",
    "    ('sigma', float64), \n",
    "    ('N', int32), \n",
    "    ('k', int32), \n",
    "    ('burn', float32),\n",
    "    ('shock_type', types.unicode_type),\n",
    "    ('shock_type_perceived', types.unicode_type),\n",
    "    ('n_sim', int32), \n",
    "    ('work_age', int32), \n",
    "    ('agg_corr', float32), \n",
    "    ('corr', float32), \n",
    "    ('theta', float32)\n",
    "     ]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     1,
     20,
     31,
     36,
     46,
     58,
     75,
     91,
     132,
     152,
     171,
     186,
     207,
     216,
     284,
     301,
     305,
     308,
     358,
     362,
     371,
     385,
     395,
     402,
     422
    ]
   },
   "outputs": [],
   "source": [
    "class LearningIncome:\n",
    "    def __init__(self,\n",
    "                 ar_paras = np.array([0.97,0.1]),\n",
    "                 N = 60):\n",
    "        self.ar_paras = ar_paras\n",
    "        self.rho = ar_paras[0]\n",
    "        self.sigma = ar_paras[1]\n",
    "        self.N = N \n",
    "        self.k = 1\n",
    "        self.burn = 0.2\n",
    "        self.n_sim = 30\n",
    "        self.shock_type = 'iid'\n",
    "        self.shock_type_perceived = 'iid'\n",
    "        self.work_age = 15\n",
    "        self.agg_corr = 1\n",
    "        self.corr = 0.9\n",
    "        self.theta = 1.5\n",
    "             \n",
    "# simulate individual time series and cross-sectional data \n",
    "\n",
    "    def Simulateiid(self):\n",
    "        ar1 = self.ar_paras\n",
    "        rho,sigma = ar1\n",
    "        N_burn = np.int(self.burn*self.N)\n",
    "        N_long = self.N + N_burn\n",
    "        simulated_pop = ARSimulator(rho,\n",
    "                                    sigma,\n",
    "                                    N_long)\n",
    "        self.simulated = simulated_pop[N_burn:]\n",
    "        return self.simulated \n",
    "    \n",
    "    def SimulateAggCorr(self):\n",
    "        ar1 = self.ar_paras\n",
    "        rho,sigma = ar1\n",
    "        N_burn = np.int(self.burn*self.N)\n",
    "        N_long = self.N + N_burn\n",
    "        sks = DrawShocks(sigma = sigma,     # size of income shock\n",
    "                         agg_corr = self.agg_corr,  # cross-sectional correlation \n",
    "                         n = self.n_sim,         # nb of people each point of time\n",
    "                         T = self.N)         # time period \n",
    "        simulated_pop = ARPanelSimulator(rho = rho,\n",
    "                                         n = self.n_sim,\n",
    "                                         T = self.N,\n",
    "                                         shocks = sks)\n",
    "        return simulated_pop[:,N_burn:]\n",
    "        \n",
    "    def SimulatePop(self):\n",
    "        self.simulated_pop = np.empty([self.n_sim,self.N])\n",
    "        if self.shock_type =='iid':\n",
    "            for i in range(self.n_sim):\n",
    "                self.simulated_pop[i,:] = self.Simulateiid()\n",
    "        if self.shock_type =='correlated':\n",
    "            self.simulated_pop = self.SimulateAggCorr()\n",
    "            \n",
    "        return self.simulated_pop\n",
    "    \n",
    "## learning based on a given sample \n",
    "    \n",
    "    def LearnPara(self,\n",
    "                  sample,\n",
    "                  which = 1): \n",
    "        n_sim,N = sample.shape\n",
    "        Y = np.asmatrix(sample[:,1:].flatten()).T\n",
    "        X = np.asmatrix(sample[:,:-1].flatten()).T\n",
    "        nobs = len(Y)\n",
    "        model = sm.OLS(Y,X)\n",
    "        rs = model.fit()\n",
    "        #print(rs.summary())\n",
    "        coeffs_est = rs.params\n",
    "        self.rs_correct = rs\n",
    "        self.errs = rs.resid.reshape(n_sim,N-1) ## residuals matrix \n",
    "        self.recent = sample[which,-1]\n",
    "        self.change = sample[which,-1] - sample[which,-2]\n",
    "        #self.change  = self.errs[which,-1]\n",
    "        \n",
    "        if self.shock_type_perceived == 'iid':\n",
    "            self.sigma2_est = np.sum(self.errs**2)/(rs.nobs-1)\n",
    "            self.D = np.eye(nobs)*self.sigma**2\n",
    "            self.D_est = np.eye(nobs)*self.sigma2_est\n",
    "            xx = np.dot(X.T,X)\n",
    "            ## regression coeffs \n",
    "            #coef_var_est0 = rs.bse**2  # using statsmodel package \n",
    "            coef_var_est1 = np.array(lg.inv(xx)*self.sigma2_est)  ## by hand \n",
    "            #coef_var_est2 = np.array(np.dot(np.dot(np.dot(np.dot(lg.inv(xx),\n",
    "            #                                     X.T),\n",
    "            #                                     self.D_est),\n",
    "            #                              X),\n",
    "            #                       lg.inv(xx)\n",
    "            #                      )) ## by general formula \n",
    "            self.coef_var_est = coef_var_est1\n",
    "            \n",
    "        if self.shock_type_perceived == 'non-independence':  ## generalized least square \n",
    "            sigma_est = np.eye(nobs)\n",
    "            for i in range(int(rs.nobs - N)):\n",
    "                sigma_est[i,i+N]= self.corr\n",
    "                sigma_est[i+N,i] = self.corr ## create correlation across people\n",
    "            #sigma_est = np.where(sigma_est == 0, \n",
    "            #                     self.corr**2, \n",
    "            #                     sigma_est)  # diagnal being 1 and off-diagnal being subjective corr\n",
    "            xx = np.dot(X.T,X)\n",
    "            xsx = np.array(lg.inv(np.dot(np.dot(X.T,\n",
    "                                                lg.inv(sigma_est)\n",
    "                                                      ),\n",
    "                                                X)\n",
    "                                        )\n",
    "                                        )  # X'sigma^-1X\n",
    "            xsy = np.array(np.dot(np.dot(X.T,\n",
    "                                         lg.inv(sigma_est)\n",
    "                                        ),\n",
    "                                  Y) # X'sigma^-1Y\n",
    "                          )\n",
    "            #coeffs_est = np.dot(xsx,\n",
    "            #                    xsy)   # beta_gls \n",
    "            \n",
    "            #err1d = Y-X*coeffs_est\n",
    "            #self.errs = err1d.reshape(n_sim,N-1)\n",
    "            self.sigma2_est = np.sum(np.array(self.errs)**2)/(rs.nobs-1)\n",
    "            self.D_est = sigma_est*self.sigma2_est\n",
    "            coef_var_est2 = np.array(np.dot(np.dot(np.dot(np.dot(lg.inv(xx),\n",
    "                                                 X.T),\n",
    "                                                 self.D_est),\n",
    "                                          X),\n",
    "                                  lg.inv(xx)   \n",
    "                                  )) ## by general formula   ## variance of ols estimate\n",
    "            coef_var_est3 = np.array(np.dot(np.dot(np.dot(np.dot(lg.inv(xsx),\n",
    "                                                 X.T),\n",
    "                                                 self.D_est),\n",
    "                                          X),\n",
    "                                  lg.inv(xsx)   \n",
    "                                  )) ## by general formula   ## variance of gls estimate\n",
    "            self.coef_var_est = coef_var_est2\n",
    "            \n",
    "        if self.shock_type_perceived == 'cluster':\n",
    "            self.sigma2_est = np.sum(self.errs**2)/(rs.nobs-1)\n",
    "            self.D_est = np.sum([np.dot(np.matrix(np.sum(sample[:,j]*self.errs[:,j])),\n",
    "                                       lg.inv(np.matrix(np.sum(sample[:,j]*self.errs[:,j]\n",
    "                                                              )\n",
    "                                                       )\n",
    "                                             )\n",
    "                                      ) for j in range(n_sim-1)])\n",
    "            xx = np.dot(X.T,X)\n",
    "            ## regression coeffs \n",
    "            coef_var_est2 = (rs.nobs-1)/(rs.nobs-self.k)*N/(N-1)*np.array(np.dot(np.dot(np.dot(np.dot(lg.inv(xx),\n",
    "                                                 X.T),\n",
    "                                                 self.D_est),\n",
    "                                          X),\n",
    "                                   lg.inv(xx)\n",
    "                                  )) ## by general formula \n",
    "            D_est_simple = self.sigma2_est*(1+self.corr*(N-1))\n",
    "            coef_var_est3 = lg.inv(xx)*D_est_simple\n",
    "            self.coef_var_est = coef_var_est3\n",
    "            \n",
    "        if self.shock_type_perceived == 'serial_correlate':\n",
    "            self.sigma2_est = np.sum(self.errs**2)/(rs.nobs-1)\n",
    "            self.D_est = np.sum([np.dot(np.matrix(np.sum(sample[i,:-1]*self.errs[i,:])),\n",
    "                                       lg.inv(np.matrix(np.sum(sample[i,:-1]*self.errs[i,:]\n",
    "                                                              )\n",
    "                                                       )\n",
    "                                             )\n",
    "                                      ) for i in range(n_sim)])\n",
    "            xx = np.dot(X.T,X)\n",
    "            ## regression coeffs \n",
    "            coef_var_est2 = (rs.nobs-1)/(rs.nobs-self.k)*N/(N-1)*np.array(np.dot(np.dot(np.dot(np.dot(lg.inv(xx),\n",
    "                                                 X.T),\n",
    "                                                 self.D_est),\n",
    "                                          X),\n",
    "                                   lg.inv(xx)\n",
    "                                  )) ## by general formula \n",
    "            self.coef_var_est = coef_var_est2\n",
    "            \n",
    "        if self.shock_type_perceived == 'attribution_biased':\n",
    "            if  self.change >= 0:  ## positive change, then i.i.d. \n",
    "                self.sigma2_est = np.sum(self.errs**2)/(rs.nobs-1)\n",
    "                self.D = np.eye(nobs)*self.sigma**2\n",
    "                self.D_est = np.eye(nobs)*self.sigma2_est\n",
    "                xx = np.dot(X.T,X)\n",
    "                ## regression coeffs \n",
    "                #coef_var_est0 = rs.bse**2  # using statsmodel package \n",
    "                coef_var_est1 = np.array(lg.inv(xx)*self.sigma2_est)  ## by hand \n",
    "                #coef_var_est2 = np.array(np.dot(np.dot(np.dot(np.dot(lg.inv(xx),\n",
    "                #                                     X.T),\n",
    "                #                                     self.D_est),\n",
    "                #                              X),\n",
    "                #                       lg.inv(xx)\n",
    "                #                      )) ## by general formula \n",
    "                self.coef_var_est = coef_var_est1\n",
    "            elif self.change < 0:\n",
    "                self.sigma2_est = np.sum(self.errs**2)/(rs.nobs-1)\n",
    "                #self.D_est = np.sum([np.dot(np.matrix(np.sum(sample[:,j]*self.errs[:,j])),\n",
    "                #                           lg.inv(np.matrix(np.sum(sample[:,j]*self.errs[:,j]\n",
    "                #                                                  )\n",
    "                #                                           )\n",
    "                #                                 )\n",
    "                #                          ) for j in range(N-1)])  ## hat omega = sum_g (sum_ng x e)(sum_ng x e)'\n",
    "                xx = np.dot(X.T,X)\n",
    "                ## regression coeffs \n",
    "                #coef_var_est2 = (rs.nobs-1)/(rs.nobs-self.k)*N/(N-1)*np.array(np.dot(np.dot(np.dot(np.dot(lg.inv(xx),\n",
    "                #                                     X.T),\n",
    "                #                                     self.D_est),\n",
    "                #                              X),\n",
    "                #                       lg.inv(xx)\n",
    "                #                      )) ## by general formula\n",
    "                D_est_simple = self.sigma2_est*(1+self.corr*(n_sim-1))\n",
    "                coef_var_est3 = lg.inv(xx)*D_est_simple\n",
    "                \n",
    "                self.coef_var_est = coef_var_est3  ## negative changes, then cluster \n",
    "        \n",
    "        if self.shock_type_perceived == 'extrapolative_attribution_biased':\n",
    "            corr = self.extrapolate(self.change/self.sigma)\n",
    "            self.sigma2_est = np.sum(self.errs**2)/(rs.nobs-1)\n",
    "            xx = np.dot(X.T,X)\n",
    "            ## regression coeffs \n",
    "            D_est_simple = self.sigma2_est*(1+corr*(n_sim-1))\n",
    "            coef_var_est3 = lg.inv(xx)*D_est_simple    \n",
    "            self.coef_var_est = coef_var_est3  ## based on the extrapolative corr            \n",
    "        \n",
    "        if self.shock_type_perceived == 'attribution_biased2':\n",
    "            if  self.change >= 0:  ## positive change, then i.i.d. \n",
    "                self.sigma2_est = np.sum(self.errs**2)/(rs.nobs-1)\n",
    "                self.D = np.eye(nobs)*self.sigma**2\n",
    "                self.D_est = np.eye(nobs)*self.sigma2_est\n",
    "                xx = np.dot(X.T,X)\n",
    "                ## regression coeffs \n",
    "                #coef_var_est0 = rs.bse**2  # using statsmodel package \n",
    "                coef_var_est1 = np.array(lg.inv(xx)*self.sigma2_est)  ## by hand \n",
    "                #coef_var_est2 = np.array(np.dot(np.dot(np.dot(np.dot(lg.inv(xx),\n",
    "                #                                     X.T),\n",
    "                #                                     self.D_est),\n",
    "                #                              X),\n",
    "                #                       lg.inv(xx)\n",
    "                #                      )) ## by general formula \n",
    "                self.coef_var_est = coef_var_est1\n",
    "            elif self.change < 0:\n",
    "                sigma_est = np.eye(nobs)\n",
    "                for i in range(int(rs.nobs - N)):\n",
    "                    sigma_est[i,i+N]= self.corr**2\n",
    "                    sigma_est[i+N,i] = self.corr**2 ## create correlation across people\n",
    "                #sigma_est = np.where(sigma_est == 0, \n",
    "                #                     self.corr**2, \n",
    "                #                     sigma_est)  # diagnal being 1 and off-diagnal being subjective corr\n",
    "                xx = np.dot(X.T,X)\n",
    "                xsx = np.array(lg.inv(np.dot(np.dot(X.T,\n",
    "                                                    lg.inv(sigma_est)\n",
    "                                                          ),\n",
    "                                                    X)\n",
    "                                            )\n",
    "                                            )  # X'sigma^-1X\n",
    "                xsy = np.array(np.dot(np.dot(X.T,\n",
    "                                             lg.inv(sigma_est)\n",
    "                                            ),\n",
    "                                      Y) # X'sigma^-1Y\n",
    "                              )\n",
    "                #coeffs_est = np.dot(xsx,\n",
    "                #                    xsy)   # beta_gls \n",
    "\n",
    "                #err1d = Y-X*coeffs_est\n",
    "                #self.errs = err1d.reshape(n_sim,N-1)\n",
    "                self.sigma2_est = np.sum(np.array(self.errs)**2)/(rs.nobs-1)\n",
    "                self.D_est = sigma_est*self.sigma2_est\n",
    "                coef_var_est2 = np.array(np.dot(np.dot(np.dot(np.dot(lg.inv(xx),\n",
    "                                                     X.T),\n",
    "                                                     self.D_est),\n",
    "                                              X),\n",
    "                                      lg.inv(xx)   \n",
    "                                      )) ## by general formula   ## variance of ols estimate\n",
    "                coef_var_est3 = np.array(np.dot(np.dot(np.dot(np.dot(lg.inv(xsx),\n",
    "                                                     X.T),\n",
    "                                                     self.D_est),\n",
    "                                              X),\n",
    "                                      lg.inv(xsx)   \n",
    "                                      )) ## by general formula   ## variance of gls estimate\n",
    "                self.coef_var_est = coef_var_est2\n",
    "        ## common estimate \n",
    "        self.paras_learned = coeffs_est\n",
    "        \n",
    "        ## forecast \n",
    "        self.var_predict_chg = self.sigma**2\n",
    "        self.var_predict_chg_est = self.sigma2_est + sample[which,-1]**2*self.coef_var_est \n",
    "        # n_sim individual-specific var\n",
    "        \n",
    "        return self.paras_learned,self.coef_var_est,self.sigma2_est\n",
    "    \n",
    "## ages and experiences \n",
    "\n",
    "    def SimulateAgePop(self):\n",
    "        minus_life = np.flip(np.arange(self.N))\n",
    "        minus_life = np.expand_dims(minus_life,\n",
    "                                    axis = 1).T\n",
    "        minus_life_pop_sim = np.repeat(minus_life,\n",
    "                                       self.n_sim,\n",
    "                                       axis = 0) ## a matrix that is to be substracted to get the ages\n",
    "        #age_pop_last = np.arange(self.n_sim)+20\n",
    "        #np.random.seed(23023)\n",
    "        age_pop_last = np.random.choice(range(20,60),\n",
    "                                        self.n_sim)\n",
    "        age_pop_last = np.expand_dims(age_pop_last,\n",
    "                                      axis =1) # a population with different ages \n",
    "        self.ages_pop_sim = age_pop_last - minus_life_pop_sim ## get the age \n",
    "        self.ages_pop_sim = np.where(self.ages_pop_sim < self.work_age, np.nan, self.ages_pop_sim)         \n",
    "        return self.ages_pop_sim\n",
    "    \n",
    "    def Experience(self): ## age_pop is a simulated matrix with people in different ages. \n",
    "        sparse_pop = np.zeros(self.n_sim,self.N)\n",
    "        for i in range(self.n_sim):\n",
    "            for j in range(self.N):\n",
    "                if j>=self.N-self.ages_pop_sim[i]:\n",
    "                    sparse_pop[i,j] = 1 \n",
    "    \n",
    "    def LearnParafromExperience(self):\n",
    "        \n",
    "        ## simulate age \n",
    "        self.SimulateAgePop()\n",
    "        \n",
    "        ## locations \n",
    "        coeffs_est = np.empty([self.n_sim,self.N])\n",
    "        sigma2_est = np.empty([self.n_sim,self.N])\n",
    "        coef_vars_est = np.empty([self.n_sim,self.N])\n",
    "        var_predict_chg_est = np.empty([self.n_sim,self.N])\n",
    "        av_past = np.empty([self.n_sim,self.N])\n",
    "        recent = np.empty([self.n_sim,self.N])\n",
    "        changes = np.empty([self.n_sim,self.N])\n",
    "        \n",
    "        for i in range(self.n_sim):\n",
    "            for j in range(self.N):\n",
    "                if self.ages_pop_sim[i,j] > self.work_age:\n",
    "                    st = np.min([idx for idx in range(j)]) ## begin of experience\n",
    "                    ed = j  ## end of experience\n",
    "                    sample_this = self.simulated_pop[:,st:ed]\n",
    "                    if sample_this.shape[1] >= 2:  ## at least two observations \n",
    "                        self.LearnPara(sample = sample_this,\n",
    "                                       which = i)\n",
    "                        coeffs_est[i,j] = self.paras_learned\n",
    "                        sigma2_est[i,j] = self.sigma2_est\n",
    "                        coef_vars_est[i,j] = self.coef_var_est\n",
    "                        var_predict_chg_est[i,j] = self.var_predict_chg_est\n",
    "                        av_past[i,j] = np.mean(sample_this[i,:])\n",
    "                        recent[i,j] =  self.recent\n",
    "                        changes[i,j] = self.change\n",
    "                else:\n",
    "                    coeffs_est[i,j] =  np.nan\n",
    "                    sigma2_est[i,j] = np.nan\n",
    "                    coef_vars_est[i,j] = np.nan\n",
    "                    var_predict_chg_est[i,j] = np.nan\n",
    "                    av_past[i,j] = np.nan\n",
    "                    recent[i,j] =  np.nan\n",
    "                    changes[i,j] = np.nan\n",
    "                    \n",
    "        self.coeffs_est = coeffs_est\n",
    "        self.sigma2s_est = sigma2_est\n",
    "        self.coef_vars_est = coef_vars_est\n",
    "        self.var_predict_chg_est = var_predict_chg_est\n",
    "        self.av_past = av_past \n",
    "        self.changes = changes\n",
    "        self.recent = recent \n",
    "        \n",
    "        return self.coeffs_est,self.coef_vars_est,self.sigma2s_est,self.var_predict_chg_est\n",
    "    \n",
    "## other functions\n",
    "    def logisticfunc(self,\n",
    "                     x):\n",
    "        return 1/(1+np.exp(-self.theta*x))\n",
    "    \n",
    "    def extrapolate(self,\n",
    "                    shock,\n",
    "                    how = 'by_size'):\n",
    "        if how =='by_size':\n",
    "            corr = 1-self.logisticfunc(shock)\n",
    "        elif how =='by_sign':\n",
    "            corr = np.array(shock < 0)  ## 0 or 1 depending on the sign \n",
    "        return corr\n",
    "    \n",
    "    def extrapolate2(self,\n",
    "                   shock,\n",
    "                   how = 'by_size'):\n",
    "        if how =='by_size':\n",
    "            corr = -erf(self.theta*shock)\n",
    "        elif how =='by_sign':\n",
    "            corr = np.array(shock < 0)  ## 0 or 1 depending on the sign \n",
    "        return corr\n",
    "    \n",
    "###############################################################\n",
    "### stand-alone functions to be jitted or for general purpose\n",
    "##############################################################\n",
    "\n",
    "@njit\n",
    "def ARSimulator(rho,\n",
    "                sigma,\n",
    "                T):\n",
    "    x = np.empty(T)\n",
    "    x[0] = 0.01\n",
    "    shocks = sigma*np.random.randn(T)\n",
    "    for i in range(T-1):\n",
    "        x[i+1] = rho*x[i] + shocks[i+1]\n",
    "    return x\n",
    "\n",
    "def MultiNormalSampler(mean,\n",
    "                       cov,\n",
    "                       size = 1):\n",
    "    L = splg.cholesky(cov)\n",
    "    Z = np.random.normal(size = (size, cov.shape[0]))\n",
    "    return Z.dot(L)+mean \n",
    "\n",
    "def DrawShocks(sigma,     # size of income shock\n",
    "               agg_corr,  # cross-sectional correlation coefficient \n",
    "               n,         # nb of people each point of time\n",
    "               T):        # length of time \n",
    "    ## correlation matrix \n",
    "    mean = np.zeros(n)\n",
    "    cov = sigma**2*agg_corr*np.ones((n,n))\n",
    "    np.fill_diagonal(cov,1)   ## diagnal being 1\n",
    "        \n",
    "    ## generate shocks that are cross-sectionally correlated \n",
    "    #shocks = np.random.multivariate_normal(mean,cov) # for a particular t\n",
    "    shocks = MultiNormalSampler(mean,cov,size = T)\n",
    "    #for t in range(T):\n",
    "    #    shocks_this_t = np.random.multivariate_normal(mean,cov) # for a particular t\n",
    "    #    shocks = np.vstack((shocks,\n",
    "    #                        shocks_this_t))\n",
    "    #shocks = shocks.T\n",
    "    return shocks \n",
    "\n",
    "@njit \n",
    "def ARPanelSimulator(rho, \n",
    "                     n,\n",
    "                     T,\n",
    "                     shocks):\n",
    "        ## generate simulated data \n",
    "        simulated_pop = np.empty((n,T))\n",
    "        simulated_pop[:,0] = 0.01\n",
    "        for i in range(n):\n",
    "            for t in range(T-1):\n",
    "                simulated_pop[i,t+1] = rho*simulated_pop[i,t] + shocks[i,t+1]\n",
    "        return simulated_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial parameters \n",
    "paras = {'theta': 40,\n",
    "        'n_sim': 200,\n",
    "        'N':60,\n",
    "        'agg_corr':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize an instance \n",
    "one = LearningIncome()\n",
    "simulated_data1 = one.Simulateiid()\n",
    "one.theta = paras['theta']\n",
    "one.n_sim = paras['n_sim']\n",
    "one.N = paras['N']\n",
    "one.agg_corr = paras['agg_corr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## simulate ar1 data \n",
    "\n",
    "plt.subplot(1,1,1)\n",
    "plt.title('one simulated sequence of income (AR1)')\n",
    "plt.plot(simulated_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Distribution of income over time')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist = plt.hist(simulated_data1)\n",
    "plt.title('Distribution of income over time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_data_pop = one.SimulatePop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Unconditional distribution')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist_pop = plt.hist(simulated_data_pop.flatten())\n",
    "plt.title('Unconditional distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A baseline model of experience-based learning\n",
    "\n",
    "If each agent knows _perfectly_ the model parameters $\\rho$ and $\\sigma$, the uncertainty about future income growth is \n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\begin{split}\n",
    "Var^*_{i,t}(\\Delta y_{i,t+1}) & =  Var^*_{i,t}(y_{i,t+1}- y_{i,t}) \\\\ \n",
    "& =  Var^*_{i,t}((\\rho-1)y_{i,t} + \\epsilon_{i,t+1}) \\\\\n",
    "& = Var^*_{i,t}(\\epsilon_{i,t+1}) \\\\\n",
    "& = \\sigma^2\n",
    "\\end{split}\n",
    "\\end{eqnarray}\n",
    "\n",
    "The superscript $*$ is the notation for perfect understanding. \n",
    "\n",
    "Under imperfect understanding and learning, both $\\rho$ and $\\sigma^2$ are unknown to agents. Therefore, the agent needs to learn about the parameters from the small panel sample experienced up to that point of the time. We represent the sample estimates of $\\rho$ and $\\sigma^2$ using $\\widehat \\rho$ and $\\hat{\\sigma}^2$. \n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\begin{split}\n",
    "Var_{i,t}(\\Delta y_{i,t+1}) & = y_{i,t-1}^2 \\widehat{Var}^{\\rho}_{i,t} + \\hat{\\sigma}^2_{i,t}\n",
    "\\end{split}\n",
    "\\end{eqnarray}\n",
    "\n",
    "The perceived risks of future income growth have two components. The first one comes from the uncertainty about the persistence parameter. The second is based on the estimated risk of a yet-unrealized shock. The first component is non-existent under perfect understanding. Notice that this source of uncertainty is scaled by the squared size of the contemporary income. It implies that the income risks are size-dependent under imperfect understanding. And the second component has its perfectly known counterpart under perfect understanding. In general, the estimates $\\hat{\\sigma}^2_{i,t}$ can be lower or higher than the true risks.  \n",
    "\n",
    "We assume the agents learn the parameters using the least square rule. We first consider the case when the agent understands that the income shocks are i.i.d. To put it differently, this is when the agent correctly specify the income model when learning. The least-square estimate of paramters are the following.\n",
    "\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\hat \\rho_{i,t} = (Y_{t-1}'Y_{t-1})^{-1}(Y_{t-1}Y_{t})\n",
    "\\end{eqnarray}\n",
    "\n",
    "The variance of sample residuls are used for estimating the income volatility $\\sigma^2$. \n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\widehat{\\sigma}^2_{i} = s^2 = \\frac{1}{N_{i,t}} \\sum \\hat e_i^2\n",
    "\\end{eqnarray}\n",
    "\n",
    "where $N_{i,t}$ is the size of the panel sample available to the agent $i$ at time t. It is equal to $n(t-c)$, the number of people in the sample times the duration of agent $i$'s career. \n",
    "\n",
    "Under i.i.d. assumption, the estimated uncertainty about the estimate is \n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\widehat {Var}^{\\rho}_{i,t} = (Y_{t-1}'Y_{t-1})^{-1}\\widehat{\\sigma}^2_{i,t}I_{N_{i}}\n",
    "\\end{eqnarray}\n",
    "\n",
    "Experience-based learning naturally introduces a mechanism for the perceived income risks to be cohort-specific and age-specific. Different generations who have experienced different realizations of the income shocks have different estimates of $Var^{\\rho}$ and $\\sigma^2$, thus differ in their uncertainty about future income. In the meantime, people at an older age are faced with a larger sample size than younger ones, this will drive the age profile of perceived risks in line with the observation that the perceived risk is lower as one grows older. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribution bias \n",
    "\n",
    "The attribution bias induces an agent to subjectively make assumptions about the correlation structure of income shocks, which may or may not be consistent with the truth. A particular manifesto of the bias, as far as this paper is concerned, is that people attribute bad luck to external causes and good luck to internal ones. The learning framework here can neatly capture this by assuming that people's subjective specification of the nature of the shocks $\\epsilon$ asymmetrically depends on the sign of the recent income change (or the realized shocks). More formally, I use superscript $\\tilde{}$ to denote perceptions under attribution bias, the bias can manifest itself in the following manner. \n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\begin{split}\n",
    "\\tilde E_{i,t}(\\epsilon_{i,t-k}\\epsilon_{j,t-k}|Y_{t-k-1}) = 0 \\quad \\forall k =0, 1,... t-c \\quad \\textrm{if} \\quad \\Delta(y_{i,t})>0 \\\\\n",
    "\\tilde E_{i,t}(\\epsilon_{i,t-k}\\epsilon_{j,t-k}|Y_{t-k-1}) > 0 \\quad \\forall k =0, 1,... t-c \\quad \\textrm{if} \\quad \\Delta(y_{i,t})<0\n",
    "\\end{split}\n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "This implies, a positive change in income induces the agent to maintain the independence assumption of the shocks, while a negative change in income makes the agent interpret the shock to be positively correlated with each other within each point of the time. Assuming the perceived correlation is the same between different people, this is equivalent to saying that the agent's subject attribution leads her to believe that the correlation across agents is $\\tilde\\delta_{i,t}$. \n",
    "\n",
    "Here, I let the attribution be contingent on the income change $\\delta y_{i,t}$. An alternative to it can be the forecast errors, $\\widehat e_{i,t}$, namely the unexpected income shock to agent $i$ at time $t$. The distinction between the two modeling techniques is indistinguishable in terms of qualitative predictions.  \n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\begin{split}\n",
    "\\tilde\\delta_{i,t} = 0 \\quad \\textrm{if} \\quad \\Delta(y_{i,t})>0 \\\\\n",
    "\\tilde\\delta_{i,t} = 1 \\quad \\textrm{if} \\quad \\Delta(y_{i,t})<0\n",
    "\\end{split}\n",
    "\\end{eqnarray}\n",
    "\n",
    "The agent still adopts the ordinary least square learning rule. Therefore, her estimate of $\\rho$ remains the same as before. However, the uncertainty about the estimate of $\\rho$ is no longer the same because of the attribution bias. Econometrically, this is equivalent to accounting for clustered standard errors across observations within each point of time. If we maintain the homoscedasticity assumption, i.e. income risks do not change over time $\\sigma$, one can derive the uncertainty about the persistence parameter as below \n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\begin{split}\n",
    "\\tilde {Var}^{\\rho}_{i,t}  = (Y_{t-1}'Y_{t-1})^{-1}\\widehat{\\sigma}^2(1+ \\tilde\\delta_{i,t}(n-1))\n",
    "\\end{split}\n",
    "\\end{eqnarray}\n",
    "\n",
    "Where $n$ is the number of observations within each time cluster, i.e. the number of people at any point of the time.\n",
    "\n",
    "One can immediately show the following:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\tilde {Var}^{\\rho}_{i,t} \\geq \\widehat {Var}^{\\rho}_{i,t} \\quad \\forall \\quad \\tilde\\delta_{i,t} \\geq 0\n",
    "\\end{eqnarray}\n",
    "\n",
    "where the equality holds as a special case when $\\tilde\\delta_{i,t} = 0$. The left hand side monotonically increases with $\\tilde \\delta_{i,t}$. \n",
    "\n",
    "In the meantime, the estimates of $\\sigma^2$ remain the same no matter if the attribution bias arises, both of which are equal to the sample average of regression residuals $s^2$. \n",
    "\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\tilde{\\sigma}^2_{i,t} = \\widehat{\\sigma}^2_{i,t}\n",
    "\\end{eqnarray}\n",
    "\n",
    "Combining both relations above, one can show the perceived risks of an unlucky person is unambiguously higher than that of a lucky one. \n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\begin{split}\n",
    "\\tilde {Var}_{i,t}(\\Delta y_{i,t+1}) & = y_{i,t-1}^2 \\tilde{Var}^{\\rho}_{i,t} + \\tilde{\\sigma}^2_{i,t} \\\\\n",
    "& \\geq \\widehat {Var}_{i,t}(\\Delta y_{i,t+1}) \n",
    "\\end{split}\n",
    "\\end{eqnarray}\n",
    "\n",
    "One way to rephrase the inequality above is that the unlucky group excessively extrapolates the realized shocks into her perception of risks. There is no distinction between the lucky and unlucky group in perceived risks without the attribution bias. In the presence of the bias, anyone who is unlucky to have just experienced a negative income change has a higher perceived risk compared to any lucky one. This is because of the asymmetric attribution embedded in the bias.\n",
    "\n",
    "We have the following predictions about the perceived income risks from the analysis. \n",
    "\n",
    "- Higher subjective correlation $\\tilde \\delta_{i,t}$ leads to higher perceived risks $\\tilde{var}_{i,t}$;\n",
    "- Higher experienced volatility, measured by $s^2 \\equiv \\tilde{\\sigma}^2_{i,t}$ leads to higher perceived income risks. This mechanism is shared by people with different degree of attribution bias. What's different between different attribution is that higher bias, i.e. higher $\\tilde \\delta_{i,t}$ induces the agent to disproprotionately extrapolate the paramter uncertainty, thus perceived risks. See the comparison between Figure \\ref{var_experience_var}. This is different from the scenario without attribution bias.  \n",
    "\n",
    "It is important to note that this difference still arises even if one assumes the underlying shocks are indeed non-independent. Although different types of income shocks have different implications as to which group correctly or mis-specifies the model, it does not alter the distinction between the lucky and unlucky group. To put it bluntly,  the underlying process determines who is over-confident or under-confident. But the lucky group is always more confident than the unlucky group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$\\\\hat \\\\delta_{i,t}$')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## simple attribution function\n",
    "\n",
    "chgs = np.linspace(-1,1,200)\n",
    "corrs = one.extrapolate(chgs,\n",
    "                       how = 'by_sign')\n",
    "\n",
    "plt.title('Attribution bias with no extrapolation')\n",
    "plt.plot(chgs,\n",
    "         corrs,\n",
    "         'r-',\n",
    "         lw = 3,\n",
    "        label = r'$\\tilde \\delta_{i}$')\n",
    "plt.axhline(0,\n",
    "            lw = 3,\n",
    "           label =r'$\\hat \\delta_{i}$')\n",
    "plt.legend(loc = 0,\n",
    "           fontsize = 15)\n",
    "plt.xlabel(r'$\\Delta y_{i,t}$',\n",
    "          fontsize = 15)\n",
    "plt.ylabel(r'$\\hat \\delta_{i,t}$',\n",
    "          fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0,
     14,
     18,
     20,
     22,
     24
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a1efa0b70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## different attributions and perceived income risks  \n",
    "\n",
    "times = 10\n",
    "corrs = np.linspace(0.01,0.99,times)\n",
    "vars_predict_est = np.empty(times)\n",
    "\n",
    "for i,corr in enumerate(corrs):\n",
    "    one.corr = corr\n",
    "    one.Simulateiid()\n",
    "    one.shock_type_perceived = 'attribution_biased'\n",
    "    one.LearnPara(sample = one.simulated_pop,\n",
    "                 which = 20)\n",
    "    vars_predict_est[i] = one.var_predict_chg_est\n",
    "\n",
    "plt.plot(corrs,\n",
    "        vars_predict_est,\n",
    "        'r--',\n",
    "        label = \"var (with bias)\")\n",
    "plt.axhline(vars_predict_est[0],\n",
    "            label = 'var (no bias)')\n",
    "plt.title('Perceived risks and attributed correlation',\n",
    "         fontsize = 15)\n",
    "plt.xlabel(r'$\\widehat\\delta$',\n",
    "          fontsize = 15)\n",
    "plt.ylabel(r'$var$',\n",
    "          fontsize = 15)\n",
    "plt.legend(loc = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrapolative attribution bias\n",
    "\n",
    "The baseline model only lets the sign of the recent income change induce attribution bias, and assumes away the possibility of the attribution bias to depend on the magnitude of the recent changes endogenously. This is reflected in the model assumption that $\\tilde \\delta_i$ could take either 1 or 0 depending on the sign of the recent income change. We could alternatively allow the attributed correlation $\\tilde \\delta_i$ to be a function of the $\\Delta(y_{i,t})$. This will open the room for income changes of different salience to induce different degrees of attribution bias. \n",
    "\n",
    "In order to capture this size-dependent pattern, I choose an attribution function that takes the following form as the following. It does not have to be this function in particular, but its properties suit the purpose here.   \n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\begin{split}\n",
    "\\tilde \\delta(\\Delta y_{i,t}) = 1- \\frac{1}{(1+e^{-\\theta \\Delta y_{i,t}})}\n",
    "\\end{split}\n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "Basically, the attribution function is a continuous variant of the logistic function with its function value bounded between $[0,1]$. It takes a s-shape and the parameter $\\theta$ governs the steepness of the s-shape around its input value. In the model, $\\theta$ is the parameter that governs the degree of the attribution bias. It takes any non-negative value. Although the quanlitative pattern induced by the attribution bias stands for any positive $\\theta$, letting it to be a parameter leaves modelers the room to recover it from subjective risks data. The attribution function under different $\\theta$ is shown in Figure \\ref{attribution_func_size}. The higher $\\theta$ is, the more sensitive the assigned correlation is to the size of the shock, thus inducing a higher dispersion of the perceived correaltion between the lucky group and unlucky group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Attribution function with different degrees of bias')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## extrapolative attribution function\n",
    "\n",
    "chgs = np.linspace(-2,2,20)\n",
    "\n",
    "thetas = np.array([0,1,2,10,20])\n",
    "\n",
    "for theta in thetas:\n",
    "    one.theta = theta\n",
    "    corrs = one.extrapolate(chgs)\n",
    "    plt.plot(chgs,\n",
    "             corrs,\n",
    "             lw = 2,\n",
    "             label = r'$\\theta =$'+str(theta))\n",
    "    #plt.axhline(0,\n",
    "    #           label =r'$\\hat \\delta_{i}$')\n",
    "    plt.legend(loc = 0,\n",
    "              fontsize = 10)\n",
    "plt.xlabel(r'$\\Delta y_{i,t}$',\n",
    "           fontsize = 15)\n",
    "plt.ylabel(r'$\\tilde \\delta_{i,t}$',\n",
    "           fontsize = 15)\n",
    "plt.title('Attribution function with different degrees of bias',\n",
    "         fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n## Estimate the model with the correctly specified model of i.i.d shock\\none.shock_type_perceived = 'iid'\\ncoeffs_est_iid,coef_vars_est_iid,sigma2s_est_iid,var_predict_chg_est_iid = one.LearnParafromExperience()\\nvar_predict_chg_est_iid_mean = np.nanmean(var_predict_chg_est_iid)\\n\\nest_iid = {'coef_est':np.nanmean(coeffs_est_iid),\\n          'coef_var_est':np.nanmean(coef_vars_est_iid),\\n          'sigma2s_est':np.nanmean(sigma2s_est_iid),\\n          'var_predict_chg_est':np.nanmean(var_predict_chg_est_iid)}\\n\\n## for cluster \\none.shock_type_perceived = 'cluster'\\ncoeffs_est_cl,coef_vars_est_cl,sigma2s_est_cl,var_predict_chg_est_cl = one.LearnParafromExperience()\\n\\n\\nest_cl = {'coef_est':np.nanmean(coeffs_est_cl),\\n          'coef_var_est':np.nanmean(coef_vars_est_cl),\\n          'sigma2s_est':np.nanmean(sigma2s_est_cl),\\n          'var_predict_chg_est':np.nanmean(var_predict_chg_est_cl)}\\n\\n## for serial_correlate \\none.shock_type_perceived = 'serial_correlate'\\ncoeffs_est_sc,coef_vars_est_sc,sigma2s_est_sc,var_predict_chg_est_sc = one.LearnParafromExperience()\\n\\nest_sc = {'coef_est':np.nanmean(coeffs_est_sc),\\n          'coef_var_est':np.nanmean(coef_vars_est_sc),\\n          'sigma2s_est':np.nanmean(sigma2s_est_sc),\\n          'var_predict_chg_est':np.nanmean(var_predict_chg_est_sc)}\\n\\n## for attribution biased\\n\\none.shock_type_perceived = 'attribution_biased'\\ncoeffs_est_ab,coef_vars_est_ab,sigma2s_est_ab,var_predict_chg_est_ab = one.LearnParafromExperience()\\n\\nest_ab = {'coef_est':np.nanmean(coeffs_est_ab),\\n          'coef_var_est':np.nanmean(coef_vars_est_ab),\\n          'sigma2s_est':np.nanmean(sigma2s_est_ab),\\n          'var_predict_chg_est':np.nanmean(var_predict_chg_est_ab)}\\n\\n\\n## for attribution biased by size \\n\\none.shock_type_perceived = 'extrapolative_attribution_biased'\\ncoeffs_est_eab,coef_vars_est_eab,sigma2s_est_eab,var_predict_chg_est_eab = one.LearnParafromExperience()\\n\\nest_eab = {'coef_est':np.nanmean(coeffs_est_eab),\\n          'coef_var_est':np.nanmean(coef_vars_est_eab),\\n          'sigma2s_est':np.nanmean(sigma2s_est_eab),\\n          'var_predict_chg_est':np.nanmean(var_predict_chg_est_eab)}\\n\\nidx = ['iid','cluster','serial correlation','attribution biased','ex_attribution biased']\\n\\nests = pd.DataFrame.from_dict([est_iid, \\n                               est_cl,\\n                               est_sc,\\n                               est_ab,\\n                              est_eab])\\nests.index = idx\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## for iid\n",
    "\"\"\"\n",
    "## Estimate the model with the correctly specified model of i.i.d shock\n",
    "one.shock_type_perceived = 'iid'\n",
    "coeffs_est_iid,coef_vars_est_iid,sigma2s_est_iid,var_predict_chg_est_iid = one.LearnParafromExperience()\n",
    "var_predict_chg_est_iid_mean = np.nanmean(var_predict_chg_est_iid)\n",
    "\n",
    "est_iid = {'coef_est':np.nanmean(coeffs_est_iid),\n",
    "          'coef_var_est':np.nanmean(coef_vars_est_iid),\n",
    "          'sigma2s_est':np.nanmean(sigma2s_est_iid),\n",
    "          'var_predict_chg_est':np.nanmean(var_predict_chg_est_iid)}\n",
    "\n",
    "## for cluster \n",
    "one.shock_type_perceived = 'cluster'\n",
    "coeffs_est_cl,coef_vars_est_cl,sigma2s_est_cl,var_predict_chg_est_cl = one.LearnParafromExperience()\n",
    "\n",
    "\n",
    "est_cl = {'coef_est':np.nanmean(coeffs_est_cl),\n",
    "          'coef_var_est':np.nanmean(coef_vars_est_cl),\n",
    "          'sigma2s_est':np.nanmean(sigma2s_est_cl),\n",
    "          'var_predict_chg_est':np.nanmean(var_predict_chg_est_cl)}\n",
    "\n",
    "## for serial_correlate \n",
    "one.shock_type_perceived = 'serial_correlate'\n",
    "coeffs_est_sc,coef_vars_est_sc,sigma2s_est_sc,var_predict_chg_est_sc = one.LearnParafromExperience()\n",
    "\n",
    "est_sc = {'coef_est':np.nanmean(coeffs_est_sc),\n",
    "          'coef_var_est':np.nanmean(coef_vars_est_sc),\n",
    "          'sigma2s_est':np.nanmean(sigma2s_est_sc),\n",
    "          'var_predict_chg_est':np.nanmean(var_predict_chg_est_sc)}\n",
    "\n",
    "## for attribution biased\n",
    "\n",
    "one.shock_type_perceived = 'attribution_biased'\n",
    "coeffs_est_ab,coef_vars_est_ab,sigma2s_est_ab,var_predict_chg_est_ab = one.LearnParafromExperience()\n",
    "\n",
    "est_ab = {'coef_est':np.nanmean(coeffs_est_ab),\n",
    "          'coef_var_est':np.nanmean(coef_vars_est_ab),\n",
    "          'sigma2s_est':np.nanmean(sigma2s_est_ab),\n",
    "          'var_predict_chg_est':np.nanmean(var_predict_chg_est_ab)}\n",
    "\n",
    "\n",
    "## for attribution biased by size \n",
    "\n",
    "one.shock_type_perceived = 'extrapolative_attribution_biased'\n",
    "coeffs_est_eab,coef_vars_est_eab,sigma2s_est_eab,var_predict_chg_est_eab = one.LearnParafromExperience()\n",
    "\n",
    "est_eab = {'coef_est':np.nanmean(coeffs_est_eab),\n",
    "          'coef_var_est':np.nanmean(coef_vars_est_eab),\n",
    "          'sigma2s_est':np.nanmean(sigma2s_est_eab),\n",
    "          'var_predict_chg_est':np.nanmean(var_predict_chg_est_eab)}\n",
    "\n",
    "idx = ['iid','cluster','serial correlation','attribution biased','ex_attribution biased']\n",
    "\n",
    "ests = pd.DataFrame.from_dict([est_iid, \n",
    "                               est_cl,\n",
    "                               est_sc,\n",
    "                               est_ab,\n",
    "                              est_eab])\n",
    "ests.index = idx\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experienced volatility and perceived risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## simulate a historical sample populated by agents at different ages \n",
    "\n",
    "## attribution bias \n",
    "one.shock_type_perceived = 'iid' #extrapolative_attribution_biased\n",
    "coeffs_est_iid,coef_vars_est_iid,sigma2s_est_iid,var_predict_chg_est_iid = one.LearnParafromExperience()\n",
    "\n",
    "ages = one.ages_pop_sim.flatten()\n",
    "sigma2s = sigma2s_est_iid.flatten()\n",
    "coef_vars_iid = coef_vars_est_iid.flatten()\n",
    "vars_predict_chg_iid = var_predict_chg_est_iid.flatten()\n",
    "av_past = one.av_past.flatten()\n",
    "recent = one.recent.flatten()\n",
    "\n",
    "## attribution bias \n",
    "\n",
    "one.shock_type_perceived = 'extrapolative_attribution_biased' #extrapolative_attribution_biased\n",
    "coeffs_est_ab,coef_vars_est_ab,sigma2s_est_ab,var_predict_chg_est_ab = one.LearnParafromExperience()\n",
    "vars_predict_chg_ab = var_predict_chg_est_ab.flatten()\n",
    "coef_vars_est_ab = coef_vars_est_ab.flatten()\n",
    "\n",
    "## average experienced volatility and the perceived income risk\n",
    "\n",
    "plt.plot(sigma2s,\n",
    "         vars_predict_chg_ab,'v',\n",
    "         label = r'$\\tilde{var}$')\n",
    "\n",
    "plt.plot(sigma2s,\n",
    "         vars_predict_chg_iid,'r*',\n",
    "         label = r'$\\widehat{var}$')\n",
    "\n",
    "plt.plot(sigma2s,\n",
    "         sigma2s,'--',\n",
    "         label = r'$\\hat \\sigma^2$')\n",
    "\n",
    "#plt.axhline(one.var_predict_chg,\n",
    "#            color ='red',\n",
    "#            label =r'$\\sigma^2$')\n",
    "\n",
    "plt.title('Experienced volatility and future perceived risk')\n",
    "plt.xlabel('average experienced volatility',\n",
    "           fontsize = 15)\n",
    "plt.ylabel('var',fontsize = 15)\n",
    "plt.legend(loc = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure illustrates the correlation between individual's experienced volatility and future perceived income risks. Blue stars represent the scenario without attribution bias, while the orange dots represent perceived risks under attribution bias. \n",
    "\n",
    "We can see individuals that have had bad income realizations extrapolate the average size of past shocks into future income risks, even though the past income shocks are the best estimate of future income risks according to the underlying model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Income realization and perceived risks \n",
    "\n",
    "Another pattern emerging as a consequence of the attribution bias is current-income-dependence, namely perceived risks differ among people with different current income levels. This is not the case without attribution bias because, under the baseline assumption, the size of the estimated income shock $\\widehat \\sigma^2$ does not depend on the level of the current income. \n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\widehat{Var}_{i,t}(y_{i,t+1}|y_{i,t}) = \\widehat \\sigma_{t}^2 \n",
    "\\end{eqnarray}\n",
    "While with attribution bias, we have the following\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\begin{split}\n",
    "\\tilde {Var_{i,t}}(y_{i,t+1}|y_{i,t-1}) & =  \\tilde Var_{i,t}(y_{i,t+1}|\\tilde\\rho y_{i,t-1}+\\widehat e_{i,t}) \\\\\n",
    "& = y_{i,t}^2 \\tilde{Var}^\\rho_{i,t} + \\tilde{\\sigma}^2 \n",
    "\\end{split}\n",
    "\\end{eqnarray}\n",
    "\n",
    "Now, the previous period income $y_{i,t}$ enters perceived income risk via two channels. The first one is the direct effect through its past-dependence for future income. The second channel is through the $\\tilde{Var}^{\\rho}_{i,t}$. Attribution bias render \\tilde{Var}^\\rho_{i,t} to decrease with realized income shock $\\widehat e_{i,t}$, which is part of the $y_{i,t}$. \n",
    "\n",
    "Figure \\ref{var_experience_income} plots the simulated correlation between the current-period income and perceived income risks for the scenario with and without attribution bias, respectively. One can immediately observe that with attribution bias let the perceived risks change with income shocks. What's interesting is that the correlation of the two is not monotone, exactly because the two effects above both play a role. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'av_past' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f1a2d8e6e0eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m plt.plot(av_past,\n\u001b[0m\u001b[1;32m      2\u001b[0m          \u001b[0mvars_predict_chg_ab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m          label = r'$\\tilde{var}$')\n\u001b[1;32m      4\u001b[0m plt.plot(av_past,\n\u001b[1;32m      5\u001b[0m          \u001b[0mvars_predict_chg_iid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'yo'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'av_past' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(av_past,\n",
    "         vars_predict_chg_ab,'r.',\n",
    "         label = r'$\\tilde{var}$')\n",
    "plt.plot(av_past,\n",
    "         vars_predict_chg_iid,'yo',\n",
    "         label = r'$\\widehat{var}$')\n",
    "plt.title('Experienced income and perceived risk',\n",
    "         fontsize = 15)\n",
    "plt.xlabel('Average past income',\n",
    "           fontsize = 15)\n",
    "plt.ylabel('var',fontsize = 15)\n",
    "plt.legend(loc = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'recent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a0011c192266>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m plt.plot(recent,\n\u001b[0m\u001b[1;32m      2\u001b[0m          \u001b[0mvars_predict_chg_ab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m          label = r'$\\tilde{var}$')\n\u001b[1;32m      4\u001b[0m plt.plot(recent,\n\u001b[1;32m      5\u001b[0m          \u001b[0mvars_predict_chg_iid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'yo'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'recent' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(recent,\n",
    "         vars_predict_chg_ab,'r.',\n",
    "         label = r'$\\tilde{var}$')\n",
    "plt.plot(recent,\n",
    "         vars_predict_chg_iid,'yo',\n",
    "         label = r'$\\widehat{var}$')\n",
    "plt.title('Recent income and perceived risk',\n",
    "         fontsize = 15)\n",
    "plt.xlabel('Recent income',\n",
    "           fontsize = 15)\n",
    "plt.ylabel('var',fontsize = 15)\n",
    "plt.legend(loc = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age and perceived risks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(one.ages_pop_sim[:,35],\n",
    "#         var_predict_chg_est1[:,35],'*')\n",
    "#plt.title('Perceived risks by age at a given time')\n",
    "#plt.xlabel('age',fontsize = 15)\n",
    "#plt.ylabel('var',fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "plt.plot(ages,vars_predict_chg_ab,\n",
    "         'r.',\n",
    "        label =r'$\\tilde{var}$')\n",
    "plt.plot(ages,vars_predict_chg_iid,\n",
    "         'y*',\n",
    "        label =r'$\\hat{var}$')\n",
    "plt.title('Age and perceived risk',\n",
    "         fontsize = 15)\n",
    "plt.xlabel('age',fontsize = 15)\n",
    "plt.ylabel('var',fontsize = 15)\n",
    "plt.legend(loc = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "plt.plot(ages,\n",
    "         coef_vars_est_ab,\n",
    "         'r.',\n",
    "        label = r'$\\tilde{var}^{\\rho}$')\n",
    "plt.plot(ages,\n",
    "         coef_vars_iid,\n",
    "         'y*',\n",
    "         label = r'$\\widehat{var}^{\\rho}$')\n",
    "plt.title('Age and parameter uncertainty',\n",
    "         fontsize = 15)\n",
    "plt.xlabel('age',fontsize = 15)\n",
    "plt.ylabel(r'$var_\\rho$',fontsize = 15)\n",
    "plt.legend(loc = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(ages,sigma2s,'*')\n",
    "#plt.xlabel('age',fontsize = 15)\n",
    "#plt.ylabel(r'$\\hat \\sigma^2$',fontsize = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate risk\n",
    "\n",
    "Previously, I assume the underlying shock is i.i.d. This section considers the implication of the attribution bias in the presence of both aggregate and idiosyncratic risks. This can be modeled by assuming that the shocks to individuals' income are positively correlated with each other at each point of the time. Denoting $\\delta>0$ as the true cross-sectional correlation of income shocks, the conditional variance-covariance of income shocks within each period is the following. \n",
    "\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\begin{split}\n",
    "E(\\epsilon_{t}'\\epsilon_{t}|Y_{t-1}) = \\Sigma^2 = \\sigma^2\\Omega \\quad \\forall t  \n",
    "\\end{split}\n",
    "\\end{eqnarray}\n",
    "\n",
    "where $\\Omega$ takes one in its diagonal and $\\delta$ in off-diagonal.  \n",
    "\n",
    "The learning process and the attribution bias all stay the same as before. Individuals specify their subjective structure of the shocks depending on the sign and size of their own experienced income changes. By the same mechanism elaborated above, a lucky person has lower perceived risks than her unlucky peer at any point of the time. This distinction between the two group stays the same even if the underlying income shocks are indeed correlated. \n",
    "\n",
    "What's new in the presence of aggregate risks lies in the behaviors of average perceived risks, because there is an aggregate shock that drives the comovement of the income shocks affecting individuals. Compared to the environment with pure idiosyncratic risks, there is no longer an approximately equal fraction of lucky and unlucky agents at a given time. Instead, the relative fraction of each group depends on the recently realized aggregate shock. If the aggregate shock is positive, more people have experienced good luck and may, therefore, underestimate the correlation (a smaller $\\tilde \\delta$). This drives down the average perceived income risks among the population. If the aggregate shock is negative, more people have just experienced income decrease thus arriving at a higher perceived income uncertainty. \n",
    "\n",
    "This naturally leads to a counter-cyclical pattern of the average perceived risks in the economy. The interplay of aggregate risks and attribution bias adds cyclical movements of the average perceived risks. The two conditions are both necessary to generate this pattern. Without the aggregate risk, both income shocks and perceived income shocks are purely idiosyncratic and they are averaged out in the aggregate level. Without attribution bias, agents symmetrically process experiences when forming future risk perceptions.\n",
    "\n",
    "Figure \\ref{average_chg_var_agg} illustrates the first point. The scatter plots showcase the correlation between average income changes across population and average perceive risks under purely idiosyncratic risks and aggregate risks. The negative correlation with aggregate risks illustrate the counter-cylical perceived risks. There is no such a correlation under purely idiosyncratic risks. Figure \\ref{average_chg_var_ab} testifies the second point. It plots the same correlation with and without attribution bias when the aggregate risk exists. Attribution bias brings about the asymmetry not seen when the bias is absent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## plot average past income changes and perceived risks with aggregate risks\n",
    "\n",
    "one.shock_type = 'correlated'  ## reset the true model to be with aggregate the risks\n",
    "one.agg_corr = 0.99\n",
    "one.SimulatePop()\n",
    "\n",
    "\n",
    "one.shock_type_perceived = 'iid' #extrapolative_attribution_biased\n",
    "coeffs_est_iid_ag,coef_vars_est_iid_ag,sigma2s_est_iid_ag,var_predict_chg_est_iid_ag = one.LearnParafromExperience()\n",
    "\n",
    "##  cross-sectional average\n",
    "vars_predict_chg_iid_av = np.nanmean(var_predict_chg_est_iid_ag,axis = 0)\n",
    "changes_iid_ag_av =  np.nanmean(one.changes,axis = 0)  ## same for the below \n",
    "\n",
    "one.theta = 100\n",
    "one.shock_type_perceived = 'extrapolative_attribution_biased' #extrapolative_attribution_biased\n",
    "coeffs_est_eab_ag,coef_vars_est_eab_ag,sigma2s_est_eab_ag,var_predict_chg_est_eab_ag = one.LearnParafromExperience()\n",
    "\n",
    "##  cross-sectional average\n",
    "vars_predict_chg_eab_av = np.nanmean(var_predict_chg_est_eab_ag,axis = 0)\n",
    "changes_eab_ag_av = np.nanmean(one.changes,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## plot\n",
    "fig, ax = plt.subplots(1,2,figsize = (15,5))\n",
    "ax2 = ax[0].twinx()\n",
    "ax[0].plot(changes_iid_ag_av,\n",
    "       'r--',\n",
    "        label = r'$\\tilde{e_{t}}$')\n",
    "ax2.plot(vars_predict_chg_iid_av,\n",
    "         'b-',\n",
    "         label = r'$\\widehat{var}_{ag}$')\n",
    "ax[0].set_xlabel('t',\n",
    "           fontsize = 15)\n",
    "ax[0].set_ylabel('average income change')\n",
    "ax2.set_ylabel('average var',fontsize = 15)\n",
    "ax[0].legend(loc = 1)\n",
    "ax2.legend(loc = 2)\n",
    "ax[0].set_title('No attribution bias')\n",
    "\n",
    "ax3 = ax[1].twinx()\n",
    "ax[1].plot(changes_eab_ag_av,\n",
    "       'r--',\n",
    "        label = r'$\\tilde{e_{t}}$')\n",
    "ax3.plot(vars_predict_chg_eab_av,\n",
    "         'k-',\n",
    "         label = r'$\\tilde{var}_{ag}$')\n",
    "ax[1].set_ylabel('average income change')\n",
    "ax3.set_ylabel('average var',fontsize = 15)\n",
    "ax[1].legend(loc = 1)\n",
    "ax3.legend(loc = 2)\n",
    "ax[1].set_title('With attribution bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## aggregate risks versus indiosyncratic risks we\n",
    "\n",
    "### only idiosyncratic risks\n",
    "one.theta = 100\n",
    "one.shock_type_perceived = 'extrapolative_attribution_biased' #extrapolative_attribution_biased common for both \n",
    "\n",
    "## shocks take either iid or aggregate  \n",
    "one.shock_type = 'iid'  ## reset the true model to be with aggregate the risks\n",
    "one.SimulatePop()\n",
    "\n",
    "coeffs_est_eab_id,coef_vars_est_eab_id,sigma2s_est_eab_id,var_predict_chg_est_eab_id = one.LearnParafromExperience()\n",
    "\n",
    "##  cross-sectional average\n",
    "vars_predict_chg_eab_id_av = np.nanmean(var_predict_chg_est_eab_id,axis = 0)\n",
    "changes_eab_id_av =  np.nanmean(one.changes,axis = 0)\n",
    "\n",
    "### aggregate risk\n",
    "one.shock_type = 'correlated'  ## reset the true model to be with aggregate the risks\n",
    "one.agg_corr = 0.8\n",
    "one.SimulatePop()\n",
    "\n",
    "coeffs_est_eab_ag,coef_vars_est_eab_ag,sigma2s_est_eab_ag,var_predict_chg_est_eab_ag = one.LearnParafromExperience()\n",
    "\n",
    "##  cross-sectional average\n",
    "vars_predict_chg_eab_av = np.nanmean(var_predict_chg_est_eab_ag,axis = 0)\n",
    "changes_eab_ag_av =  np.nanmean(one.changes,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## plot idiosyncratic risks and aggregate risks \n",
    "fig, ax = plt.subplots(1,2,figsize = (15,5))\n",
    "ax2 = ax[0].twinx()\n",
    "ax[0].plot(changes_eab_id_av,\n",
    "       'r--',\n",
    "        label = r'$\\tilde{e_{t}}$')\n",
    "ax2.plot(vars_predict_chg_eab_id_av,\n",
    "         'b-',\n",
    "         label = r'$\\widehat{var}_{ag}$')\n",
    "ax[0].set_xlabel('t',\n",
    "           fontsize = 15)\n",
    "ax[0].set_ylabel('average income change')\n",
    "ax2.set_ylabel('average var',fontsize = 15)\n",
    "ax[0].legend(loc = 1)\n",
    "ax2.legend(loc = 2)\n",
    "ax[0].set_title('Idiosyncratic risks with attribution bias')\n",
    "\n",
    "ax3 = ax[1].twinx()\n",
    "ax[1].plot(changes_eab_ag_av,\n",
    "       'r--',\n",
    "        label = r'$\\tilde{e_{t}}$')\n",
    "ax3.plot(vars_predict_chg_eab_av,\n",
    "         'k-',\n",
    "         label = r'$\\widehat{var}_{ag}$')\n",
    "ax[1].set_ylabel('average income change')\n",
    "ax3.set_ylabel('average var',fontsize = 15)\n",
    "ax[1].legend(loc = 1)\n",
    "ax3.legend(loc = 2)\n",
    "ax[1].set_title('Aggregate risks with attribution bias')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
